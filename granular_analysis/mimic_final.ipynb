{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HWtLNGBOKNFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95792333-113a-49a6-d331-44256849dd9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Read files\n",
        "  test_df = pd.read_csv('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_24.csv')\n",
        "  preds_df = pd.read_csv('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_24.csv')\n",
        "  admission_df = pd.read_csv('/content/drive/MyDrive/UM2ii/CXR Granular Bias/admissions.csv.gz', compression='gzip')\n",
        "  admission_df = admission_df[['subject_id', 'race']]\n",
        "  admission_df = admission_df.rename(columns={\"race\": \"Race\"})\n",
        "  admission_df = admission_df.drop_duplicates()\n",
        "  df = pd.merge(test_df, preds_df)\n",
        "  df['subject_id'] = [i[2][1:] for i in df.path.str.split('/')]\n",
        "  df['subject_id'] = df['subject_id'].astype(int)\n",
        "\n",
        "  # There are individuals who inconsitently report their race (granular and course); will exclude\n",
        "  admission_df = admission_df[~admission_df['subject_id'].duplicated(keep=False)]\n",
        "\n",
        "  df = pd.merge(df, admission_df, how = \"left\", on = 'subject_id')\n",
        "  df = df[df.Race != 'OTHER']\n",
        "  df = df[df.Race != 'UNKNOWN']\n",
        "  df = df[df.Race != 'UNABLE TO OBTAIN']\n",
        "  df = df[df.Race != 'MULTIPLE RACE/ETHNICITY']\n",
        "  df = df[df.Race != 'PATIENT DECLINED TO ANSWER']\n",
        "  df = df[df.Race != 'AMERICAN INDIAN/ALASKA NATIVE']\n",
        "  df = df[df.Race != 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER']\n",
        "\n",
        "print(\"In our test set, we have \" + str(sum(df.Race.value_counts())) + \" individuals with a documented race/ethnicity.\" )\n",
        "print(\"The proportion of each individuals in each documented race/ethnicity is as follows:\")\n",
        "print(df.Race.value_counts()/sum(df.Race.value_counts()))\n",
        "print()\n",
        "print(\"The number of each individuals in each documented race/ethnicity is as follows:\")\n",
        "print(df.Race.value_counts())"
      ],
      "metadata": {
        "id": "ZRpis9HYTRbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d82617-994b-4840-bfa3-44f6eb1ce5d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In our test set, we have 25888 individuals with a documented race/ethnicity.\n",
            "The proportion of each individuals in each documented race/ethnicity is as follows:\n",
            "WHITE                                 0.690938\n",
            "BLACK/AFRICAN AMERICAN                0.172126\n",
            "HISPANIC/LATINO - DOMINICAN           0.017228\n",
            "WHITE - OTHER EUROPEAN                0.016533\n",
            "HISPANIC/LATINO - PUERTO RICAN        0.015104\n",
            "ASIAN - CHINESE                       0.012400\n",
            "WHITE - RUSSIAN                       0.012361\n",
            "BLACK/CAPE VERDEAN                    0.011627\n",
            "BLACK/CARIBBEAN ISLAND                0.009155\n",
            "ASIAN                                 0.009000\n",
            "ASIAN - SOUTH EAST ASIAN              0.005060\n",
            "BLACK/AFRICAN                         0.004674\n",
            "HISPANIC OR LATINO                    0.003824\n",
            "HISPANIC/LATINO - GUATEMALAN          0.002974\n",
            "PORTUGUESE                            0.002472\n",
            "ASIAN - ASIAN INDIAN                  0.002434\n",
            "WHITE - BRAZILIAN                     0.002047\n",
            "HISPANIC/LATINO - CUBAN               0.001777\n",
            "WHITE - EASTERN EUROPEAN              0.001584\n",
            "ASIAN - KOREAN                        0.001506\n",
            "HISPANIC/LATINO - SALVADORAN          0.001275\n",
            "HISPANIC/LATINO - MEXICAN             0.001236\n",
            "HISPANIC/LATINO - HONDURAN            0.000888\n",
            "HISPANIC/LATINO - COLUMBIAN           0.000811\n",
            "SOUTH AMERICAN                        0.000657\n",
            "HISPANIC/LATINO - CENTRAL AMERICAN    0.000309\n",
            "Name: Race, dtype: float64\n",
            "\n",
            "The number of each individuals in each documented race/ethnicity is as follows:\n",
            "WHITE                                 17887\n",
            "BLACK/AFRICAN AMERICAN                 4456\n",
            "HISPANIC/LATINO - DOMINICAN             446\n",
            "WHITE - OTHER EUROPEAN                  428\n",
            "HISPANIC/LATINO - PUERTO RICAN          391\n",
            "ASIAN - CHINESE                         321\n",
            "WHITE - RUSSIAN                         320\n",
            "BLACK/CAPE VERDEAN                      301\n",
            "BLACK/CARIBBEAN ISLAND                  237\n",
            "ASIAN                                   233\n",
            "ASIAN - SOUTH EAST ASIAN                131\n",
            "BLACK/AFRICAN                           121\n",
            "HISPANIC OR LATINO                       99\n",
            "HISPANIC/LATINO - GUATEMALAN             77\n",
            "PORTUGUESE                               64\n",
            "ASIAN - ASIAN INDIAN                     63\n",
            "WHITE - BRAZILIAN                        53\n",
            "HISPANIC/LATINO - CUBAN                  46\n",
            "WHITE - EASTERN EUROPEAN                 41\n",
            "ASIAN - KOREAN                           39\n",
            "HISPANIC/LATINO - SALVADORAN             33\n",
            "HISPANIC/LATINO - MEXICAN                32\n",
            "HISPANIC/LATINO - HONDURAN               23\n",
            "HISPANIC/LATINO - COLUMBIAN              21\n",
            "SOUTH AMERICAN                           17\n",
            "HISPANIC/LATINO - CENTRAL AMERICAN        8\n",
            "Name: Race, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The number of 'No Finding' Labels in each documented race/ethnicity is as follows:\")\n",
        "df = df[df.Race.notna()]\n",
        "for race in sorted(df.Race.unique()):\n",
        "  temp_df = df[df.Race==race]\n",
        "  print(str(race) + ' ' + str(sum(temp_df['No Finding']==1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vmnd1kpdPA9",
        "outputId": "9c429b1d-ef95-45f4-acfb-80516ebf6815"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 'No Finding' Labels in each documented race/ethnicity is as follows:\n",
            "ASIAN 93\n",
            "ASIAN - ASIAN INDIAN 30\n",
            "ASIAN - CHINESE 122\n",
            "ASIAN - KOREAN 18\n",
            "ASIAN - SOUTH EAST ASIAN 56\n",
            "BLACK/AFRICAN 69\n",
            "BLACK/AFRICAN AMERICAN 2089\n",
            "BLACK/CAPE VERDEAN 151\n",
            "BLACK/CARIBBEAN ISLAND 71\n",
            "HISPANIC OR LATINO 59\n",
            "HISPANIC/LATINO - CENTRAL AMERICAN 4\n",
            "HISPANIC/LATINO - COLUMBIAN 11\n",
            "HISPANIC/LATINO - CUBAN 19\n",
            "HISPANIC/LATINO - DOMINICAN 158\n",
            "HISPANIC/LATINO - GUATEMALAN 30\n",
            "HISPANIC/LATINO - HONDURAN 12\n",
            "HISPANIC/LATINO - MEXICAN 16\n",
            "HISPANIC/LATINO - PUERTO RICAN 200\n",
            "HISPANIC/LATINO - SALVADORAN 17\n",
            "PORTUGUESE 24\n",
            "SOUTH AMERICAN 13\n",
            "WHITE 6304\n",
            "WHITE - BRAZILIAN 14\n",
            "WHITE - EASTERN EUROPEAN 20\n",
            "WHITE - OTHER EUROPEAN 155\n",
            "WHITE - RUSSIAN 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "def wauc(true, preds):\n",
        "  test_df = pd.read_csv(true)\n",
        "  preds_df = pd.read_csv(preds)\n",
        "  return metrics.roc_auc_score(y_true = test_df.drop('path', axis=1), y_score = preds_df.drop('path', axis=1),  average='macro', multi_class='ovr')\n",
        "\n",
        "\n",
        "auc_24 = wauc('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_24.csv', '/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/preds_24.csv')\n",
        "auc_36 = wauc('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_36.csv', '/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/preds_36.csv')\n",
        "auc_70 = wauc('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_70.csv', '/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/preds_70.csv')\n",
        "auc_88 = wauc('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_88.csv', '/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/preds_88.csv')\n",
        "auc_100 = wauc('/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/True_100.csv', '/content/drive/MyDrive/UM2ii/CXR Granular Bias/MIMIC/preds_100.csv')\n",
        "\n",
        "print('Average AUC of MIMIC-trained models applied onto MIMIC test set: ' + str(np.mean([auc_24, auc_36, auc_70, auc_88, auc_100])))\n",
        "confidence_interval = stats.t.interval(0.95, len([auc_24, auc_36, auc_70, auc_88, auc_100])-1, loc=np.mean([auc_24, auc_36, auc_70, auc_88, auc_100]), scale=stats.sem([auc_24, auc_36, auc_70, auc_88, auc_100]))\n",
        "\n",
        "# Print the confidence interval\n",
        "print(\"95% Confidence Interval:\", confidence_interval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAMpv-IgCWIL",
        "outputId": "c22be356-434e-48b0-a1c5-83ee785108bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average AUC of MIMIC-trained models applied onto MIMIC test set: 0.8277203537531038\n",
            "95% Confidence Interval: (0.8259063416143976, 0.8295343658918101)\n"
          ]
        }
      ]
    }
  ]
}